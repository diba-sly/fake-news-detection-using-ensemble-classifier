{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67217fef",
   "metadata": {},
   "source": [
    "Loading data from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55898de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"sample_data/train.tsv\", sep=\"\\t\", header=None)\n",
    "data_valid = pd.read_csv(\"sample_data/valid.tsv\", sep=\"\\t\", header=None)\n",
    "data_test = pd.read_csv(\"sample_data/test.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee36212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                                   3               4                     5   \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "\n",
       "         6           7     8     9      10     11   12               13  \n",
       "0     Texas  republican   0.0   1.0    0.0    0.0  0.0         a mailer  \n",
       "1  Virginia    democrat   0.0   0.0    1.0    1.0  0.0  a floor speech.  \n",
       "2  Illinois    democrat  70.0  71.0  160.0  163.0  9.0           Denver  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing sample train data before preprocessing\n",
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb033dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing sample train data counts\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10a747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with label false is: 1995\n",
      "The number of rows with label pants-fire is: 839\n",
      "The number of rows with label true is: 1676\n",
      "The number of rows with label mostly-true is: 1962\n",
      "The number of rows with label half-true is: 2114\n",
      "The number of rows with label barely-true is: 1654\n"
     ]
    }
   ],
   "source": [
    "#Viewing count of data in seprate of labels\n",
    "# Filter the DataFrame based on the label\n",
    "filtered_data1 = data_train[data_train.iloc[:, 1] ==  'false']\n",
    "filtered_data2 = data_train[data_train.iloc[:, 1]  == \"pants-fire\"]\n",
    "filtered_data3 = data_train[data_train.iloc[:, 1]  == \"true\"]\n",
    "filtered_data4 = data_train[data_train.iloc[:, 1]  == \"mostly-true\"]\n",
    "filtered_data5 = data_train[data_train.iloc[:, 1]  == \"half-true\"]\n",
    "filtered_data6 = data_train[data_train.iloc[:, 1]  == \"barely-true\"]\n",
    "# Display the result\n",
    "print(f\"The number of rows with label false is: {filtered_data1.shape[0]}\")\n",
    "print(f\"The number of rows with label pants-fire is: {filtered_data2.shape[0]}\")\n",
    "print(f\"The number of rows with label true is: {filtered_data3.shape[0]}\")\n",
    "print(f\"The number of rows with label mostly-true is: {filtered_data4.shape[0]}\")\n",
    "print(f\"The number of rows with label half-true is: {filtered_data5.shape[0]}\")\n",
    "print(f\"The number of rows with label barely-true is: {filtered_data6.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e915e263",
   "metadata": {},
   "source": [
    "convert 6 classes to 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23adf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_classes(dataset):\n",
    "    #Creating new column called 'label' with 1 for true and mostly-true values, else 0 i.e. 1=real, 0=fake\n",
    "    dataset['label']=[1 if x==\"true\"or x==\"mostly-true\" else 0 for x in dataset[1]]\n",
    "    \n",
    "    #Dealing with empty datapoints for metadata columns - subject, speaker, job, state,affiliation, context\n",
    "    meta = []\n",
    "    for i in range(len(dataset)):\n",
    "      subject = dataset[3][i]\n",
    "      if subject == 0:\n",
    "          subject = 'None'\n",
    "\n",
    "      speaker =  dataset[4][i]\n",
    "      if speaker == 0:\n",
    "          speaker = 'None'\n",
    "\n",
    "      job =  dataset[5][i]\n",
    "      if job == 0:\n",
    "          job = 'None'\n",
    "\n",
    "      state =  dataset[6][i]\n",
    "      if state == 0:\n",
    "          state = 'None'\n",
    "\n",
    "      affiliation =  dataset[7][i]\n",
    "      if affiliation == 0:\n",
    "          affiliation = 'None'\n",
    "\n",
    "      context =  dataset[13][i]\n",
    "      if context == 0 :\n",
    "          context = 'None'\n",
    "\n",
    "      meta.append(str(subject) + ' ' + str(speaker) + ' ' + str(job) + ' ' + str(state) + ' ' + str(affiliation) + ' ' + str(context)) #combining all the meta data columns into a single column\n",
    "  \n",
    "    #Adding cleaned and combined metadata column to the dataset\n",
    "    dataset[14] = meta\n",
    "    dataset[\"sentence\"] = dataset[14].astype('str')+\" \"+dataset[2] #Combining metadata and the text columns into single columns\n",
    "\n",
    "    #Dropping unwanted columns\n",
    "    dataset = dataset.drop(labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14] ,axis=1)\n",
    "    dataset.dropna() #Dropping if there are still any null values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab54793",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abortion dwayne-bohac State representative Tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>energy,history,job-accomplishments scott-surov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>foreign-policy barack-obama President Illinois...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  abortion dwayne-bohac State representative Tex...\n",
       "1      0  energy,history,job-accomplishments scott-surov...\n",
       "2      1  foreign-policy barack-obama President Illinois..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying reduce_classes to the raw data - train, valid and test sets\n",
    "data_train = combine_classes(data_train)\n",
    "data_valid = combine_classes(data_valid)\n",
    "data_test = combine_classes(data_test)\n",
    "data_train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c06371b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.644727\n",
       "1    0.355273\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing count of data in seprate of labels\n",
    "data_train['label'].value_counts(normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc847d3",
   "metadata": {},
   "source": [
    "Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a96a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def data_preprocessing(dataset):\n",
    "    preprocessed_texts = []\n",
    "    for text in dataset:\n",
    "        # convert to lowercase\n",
    "        text = text.lower()    \n",
    "        # tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "        # remove punctuation and irrelevant characters\n",
    "        filtered_tokens = [token for token in tokens if token.isalnum()]\n",
    "        # remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [token for token in filtered_tokens if not token in stop_words]\n",
    "        # lemmatize tokens\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        filtered_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "        # stem tokens\n",
    "        stemmer = PorterStemmer()\n",
    "        filtered_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "        # join tokens back into string\n",
    "        preprocessed_text = ' '.join(filtered_tokens)\n",
    "        preprocessed_texts.append(preprocessed_text)\n",
    "    return preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166413b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abort state repres texa republican mailer say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>energi histori state deleg virginia democrat f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>presid illinoi democrat denver hillari clinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>nan nan none news releas health care reform le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>economi job nan florida democrat interview cnn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  abort state repres texa republican mailer say ...\n",
       "1      0  energi histori state deleg virginia democrat f...\n",
       "2      1  presid illinoi democrat denver hillari clinton...\n",
       "3      0  nan nan none news releas health care reform le...\n",
       "4      0  economi job nan florida democrat interview cnn..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying pre-processing to the raw data - train, valid and test sets\n",
    "data_train['sentence'] = data_preprocessing(data_train['sentence'])\n",
    "data_valid['sentence'] = data_preprocessing(data_valid['sentence'])\n",
    "data_test['sentence'] = data_preprocessing(data_test['sentence'])\n",
    "#Sample data after preprocessing\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687b1fb",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "185c51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def feature_engineering(dataset):\n",
    "    preprocessed_texts = dataset['sentence']   \n",
    "    tfidf_vect = TfidfVectorizer(ngram_range=(2, 2), max_features=150)\n",
    "    tfidf_matrix = tfidf_vect.fit_transform(preprocessed_texts)\n",
    "    tfidf_matrix.sort_indices()\n",
    "    vocab_size = len(tfidf_vect.vocabulary_)\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "403c387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reduce_dimension_SVD(data_matrix):\n",
    "    svd_model = TruncatedSVD(n_components=200)\n",
    "    svd_matrix = svd_model.fit_transform(data_matrix)\n",
    "    return svd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc33059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "#Applying feature_engineering to the preproccessed data - train, valid and test sets\n",
    "X_features_train = feature_engineering(data_train)\n",
    "X_features_valid = feature_engineering(data_valid)\n",
    "X_features_test = feature_engineering(data_test)\n",
    "\n",
    "# X_features_train = reduce_dimension_SVD(X_features_train)\n",
    "# X_features_valid = reduce_dimension_SVD(X_features_valid)\n",
    "# X_features_test = reduce_dimension_SVD(X_features_test)\n",
    "print(X_features_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2b8be",
   "metadata": {},
   "source": [
    "Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a539f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "def create_ensemble_models(X_train, y_train,X_val, y_val):\n",
    "    num_models = 3\n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, 100, input_length=max_len))\n",
    "        model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, name=f'lstm_layer_{i}'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=64)\n",
    "\n",
    "        models.append(model)\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e946dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_ensemble_models(X_valid, X_test, y_valid, y_test, models):\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_ensemble_valid = np.zeros_like(y_valid, dtype = np.float64)\n",
    "    for model in models:\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        y_pred_ensemble_valid += np.squeeze((y_pred_valid > 0.5).astype(int))\n",
    "\n",
    "    y_pred_ensemble_valid /= len(models)\n",
    "    y_pred_ensemble_valid = np.round(y_pred_ensemble_valid).astype(int)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_ensemble = np.zeros_like(y_test, dtype=np.float64)\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_ensemble += np.squeeze((y_pred > 0.5).astype(int))\n",
    "\n",
    "    y_pred_ensemble /= 3\n",
    "    y_pred_ensemble = np.round(y_pred_ensemble).astype(int)\n",
    "\n",
    "    return y_pred_ensemble_valid, y_pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c6ca766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preprocess the data\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(data_train['sentence'])\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# X_train = tokenizer.texts_to_sequences(data_train['sentence'])\n",
    "# X_valid = tokenizer.texts_to_sequences(data_valid['sentence'])\n",
    "# X_test = tokenizer.texts_to_sequences(data_test['sentence'])\n",
    "vocab_size = 150\n",
    "X_train = X_features_train\n",
    "X_valid = X_features_valid\n",
    "X_test = X_features_test\n",
    "\n",
    "# max_len = 150  # Define the maximum sequence length\n",
    "# X_train = pad_sequences(X_features_train, maxlen=max_len)\n",
    "# X_valid = pad_sequences(X_features_valid, maxlen=max_len)\n",
    "# X_test = pad_sequences(X_features_test, maxlen=max_len)\n",
    "\n",
    "y_train = np.array(data_train['label'])  # Convert to numpy array\n",
    "y_valid = np.array(data_valid['label'])  # Convert to numpy array\n",
    "y_test = np.array(data_test['label'])  # Convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36219cc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160/160 [==============================] - 77s 468ms/step - loss: 0.6527 - accuracy: 0.6424 - val_loss: 0.6382 - val_accuracy: 0.6729\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 89s 553ms/step - loss: 0.6513 - accuracy: 0.6447 - val_loss: 0.6345 - val_accuracy: 0.6729\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 91s 572ms/step - loss: 0.6514 - accuracy: 0.6447 - val_loss: 0.6326 - val_accuracy: 0.6729\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 91s 571ms/step - loss: 0.6512 - accuracy: 0.6447 - val_loss: 0.6354 - val_accuracy: 0.6729\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 95s 593ms/step - loss: 0.6512 - accuracy: 0.6447 - val_loss: 0.6345 - val_accuracy: 0.6729\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 90s 547ms/step - loss: 0.6525 - accuracy: 0.6434 - val_loss: 0.6336 - val_accuracy: 0.6729\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 99s 617ms/step - loss: 0.6514 - accuracy: 0.6447 - val_loss: 0.6326 - val_accuracy: 0.6729\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 142s 890ms/step - loss: 0.6513 - accuracy: 0.6447 - val_loss: 0.6369 - val_accuracy: 0.6729\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 142s 886ms/step - loss: 0.6513 - accuracy: 0.6447 - val_loss: 0.6349 - val_accuracy: 0.6729\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 141s 879ms/step - loss: 0.6517 - accuracy: 0.6447 - val_loss: 0.6335 - val_accuracy: 0.6729\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 161s 925ms/step - loss: 0.6528 - accuracy: 0.6430 - val_loss: 0.6359 - val_accuracy: 0.6729\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 146s 911ms/step - loss: 0.6514 - accuracy: 0.6447 - val_loss: 0.6347 - val_accuracy: 0.6729\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 147s 919ms/step - loss: 0.6514 - accuracy: 0.6447 - val_loss: 0.6331 - val_accuracy: 0.6729\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 162s 1s/step - loss: 0.6512 - accuracy: 0.6447 - val_loss: 0.6343 - val_accuracy: 0.6729\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 155s 967ms/step - loss: 0.6513 - accuracy: 0.6447 - val_loss: 0.6398 - val_accuracy: 0.6729\n"
     ]
    }
   ],
   "source": [
    "#Part2 : Create ensemble model\n",
    "models = create_ensemble_models(X_train, y_train,X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4ccc36b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a75208a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a1687bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "#Visualizing\n",
    "plot_model(models[0], show_shapes=True, to_file='model-arch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01509fa7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 36ms/step\n",
      "41/41 [==============================] - 2s 36ms/step\n",
      "41/41 [==============================] - 2s 38ms/step\n",
      "40/40 [==============================] - 1s 37ms/step\n",
      "40/40 [==============================] - 1s 36ms/step\n",
      "40/40 [==============================] - 1s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_ensemble_valid, y_pred_ensemble = predict_ensemble_models(X_valid, X_test, y_valid, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "964e3603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16844/2065525717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Set the x-axis tick labels to the class labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Set the plot title and axes labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[1;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[0;32m   1812\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1709\u001b[0m             \u001b[1;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1711\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1712\u001b[0m                     \u001b[1;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m                     \u001b[1;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (2)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Visualizing distribution of predeiction of ensemble clas\n",
    "class_counts = np.bincount(y_pred_ensemble)\n",
    "# Create a bar plot\n",
    "plt.bar(range(len(class_counts)), class_counts)\n",
    "class_labels = ['Fake', 'Real']\n",
    "\n",
    "# Set the x-axis tick labels to the class labels\n",
    "plt.xticks(range(len(class_counts)), class_labels)\n",
    "\n",
    "# Set the plot title and axes labels\n",
    "plt.title('Distribution of Classifications')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e6974bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model2 - Ensemble F1-score: 0.6456195737963694\n",
      "Model2 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.78       818\n",
      "           1       0.00      0.00      0.00       449\n",
      "\n",
      "    accuracy                           0.65      1267\n",
      "   macro avg       0.32      0.50      0.39      1267\n",
      "weighted avg       0.42      0.65      0.51      1267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Print classification report\n",
    "f_score = f1_score(data_test['label'], y_pred_ensemble, average='micro')\n",
    "print(\"Model2 - Ensemble F1-score:\", f_score)\n",
    "print(\"Model2 - Classification Report:\")\n",
    "print(classification_report(data_test['label'], y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f598d40",
   "metadata": {},
   "source": [
    "MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de4e01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def build_mlp():\n",
    "    # Step 1: increase the training data with ensemble predictions\n",
    "    X_train_increased = np.concatenate((X_valid, y_pred_ensemble_valid[:X_valid.getnnz()].reshape(-1, 1)), axis=1)\n",
    "\n",
    "    mlp_classifier = MLPClassifier()\n",
    "    mlp_classifier.fit(X_train_increased, y_valid)\n",
    "\n",
    "    X_test_increased = np.concatenate((X_test, y_pred_ensemble[:X_test.getnnz()].reshape(-1, 1)), axis=1)\n",
    "    #X_test_increased = np.concatenate([X_test] + reshaped_weights + [y_pred_ensemble[:len(X_test)].reshape(-1, 1)], axis=1)\n",
    "\n",
    "    mlp_predictions = mlp_classifier.predict(X_test_increased)\n",
    "    return mlp_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e99636bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16844/792287514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlp_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_mlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16844/2994162132.py\u001b[0m in \u001b[0;36mbuild_mlp\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_mlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Step 1: increase the training data with ensemble predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX_train_increased\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_ensemble_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmlp_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\diba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "mlp_predictions = build_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69097df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate F-score and accuracy\n",
    "f_score = f1_score(y_test, mlp_predictions, average='micro')\n",
    "accuracy = accuracy_score(y_test, mlp_predictions)\n",
    "print(classification_report(y_test, mlp_predictions))\n",
    "\n",
    "print(\"Model2 - MLP F-score:\", f_score)\n",
    "print(\"Model2 - MLP Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f92f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
